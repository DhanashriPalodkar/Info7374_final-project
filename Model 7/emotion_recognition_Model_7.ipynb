{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion_recognition Model 7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3Vr_qaNOSymq",
        "colab_type": "code",
        "outputId": "c0a1fabd-784e-4d4d-fbd5-4f85e4b7ccc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pydrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.4)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (1.12.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xCgZWfrOS7fY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "import tensorflow as tf\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U4X0mBskTAgO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zip_file = drive.CreateFile({'id': '1C5FOGXLAAhvdaOuTWukGysyuj1NjIpVy'})\n",
        "zip_file.GetContentFile('complete_data_reduced.zip')\n",
        "validation_file = drive.CreateFile({'id':'1Xiy766wWCAo8gcNSyEFzwn2xaUHtxXqx'})\n",
        "validation_file.GetContentFile('validation_reduced.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q7_njATeRQId",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !unzip 'complete_data_reduced.zip'\n",
        "# !unzip 'validation_reduced.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bOex6BK6VlVm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e3a5ca3-bc1c-423e-e9a6-04afb3fa8261"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.utils.np_utils import to_categorical  \n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Convolution2D,SeparableConv2D,Conv2D\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers.pooling import MaxPooling2D,AveragePooling2D,GlobalAveragePooling2D\n",
        "from keras.layers import BatchNormalization,Activation,Input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JntNFIicVrAZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import glob,string\n",
        "\n",
        "## file paths training data\n",
        "angry_path = 'combined_data_reduced/angry/*'\n",
        "closed_path = 'combined_data_reduced/closed/*'\n",
        "disgust_path = 'combined_data_reduced/disgusted/*'\n",
        "fear_path = 'combined_data_reduced/fearful/*'\n",
        "happy_path = 'combined_data_reduced/happy/*'\n",
        "neutral_path = 'combined_data_reduced/neutral/*'\n",
        "sad_path = 'combined_data_reduced/sad/*'\n",
        "surprised_path = 'combined_data_reduced/surprised/*'\n",
        "\n",
        "## file path validation\n",
        "angry_path_val = 'validation_reduced/angry/*'\n",
        "closed_path_val = 'validation_reduced/closed/*'\n",
        "disgust_path_val = 'validation_reduced/disgusted/*'\n",
        "fear_path_val = 'validation_reduced/fearful/*'\n",
        "happy_path_val = 'validation_reduced/happy/*'\n",
        "neutral_path_val = 'validation_reduced/neutral/*'\n",
        "sad_path_val = 'validation_reduced/sad/*'\n",
        "surprised_path_val = 'validation_reduced/surprised/*'\n",
        "\n",
        "\n",
        "#list files training\n",
        "angry_files=glob.glob(angry_path)\n",
        "closed_files = glob.glob(closed_path)\n",
        "disgust_files = glob.glob(disgust_path)\n",
        "fear_files = glob.glob(fear_path)\n",
        "happy_files = glob.glob(happy_path)\n",
        "neutral_files = glob.glob(neutral_path)\n",
        "sad_files = glob.glob(sad_path)\n",
        "surprised_path = glob.glob(surprised_path)\n",
        "\n",
        "#list files validation\n",
        "angry_files_val=glob.glob(angry_path_val)\n",
        "closed_files_val = glob.glob(closed_path_val)\n",
        "disgust_files_val = glob.glob(disgust_path_val)\n",
        "fear_files_val = glob.glob(fear_path_val)\n",
        "happy_files_val = glob.glob(happy_path_val)\n",
        "neutral_files_val = glob.glob(neutral_path_val)\n",
        "sad_files_val = glob.glob(sad_path_val)\n",
        "surprised_path_val = glob.glob(surprised_path_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PDkYWEeTVvBj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_epoch = 75\n",
        "\n",
        "training_directory='combined_data_reduced'\n",
        "validation_directory = 'validation_reduced'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ru_8yHgMV0TH",
        "colab_type": "code",
        "outputId": "11d66b30-f460-46c5-fc08-fcb7ef51558c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                        featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True\n",
        "                                  )\n",
        "val_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                        featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True\n",
        "                                )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        training_directory,\n",
        "        target_size=(48,48),\n",
        "        batch_size=batch_size,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_directory,\n",
        "        target_size=(48,48),\n",
        "        batch_size=batch_size,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 31527 images belonging to 8 classes.\n",
            "Found 7591 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZXcIFsEaV4kV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=(2, 2), activation='relu'))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(256, kernel_size=(1, 1), activation='relu'))\n",
        "   \n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(8, activation='softmax'))\n",
        " \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SSLRVTxxV9aq",
        "colab_type": "code",
        "outputId": "672f9617-6ec6-42b1-9aff-dfc209ebf75f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "#model = create_model2()\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 46, 46, 32)        320       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 22, 22, 128)       16512     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 256)       33024     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 30976)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               7930112   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 2056      \n",
            "=================================================================\n",
            "Total params: 7,982,024\n",
            "Trainable params: 7,982,024\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7DkEkeU0WCOY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x_H-XrZ9WGTM",
        "colab_type": "code",
        "outputId": "7ae53a4d-b409-44f4-adc7-e6fc1d13643a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir 'trained_models'"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘trained_models’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "us52K9wRWJSN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "patience =12\n",
        "\n",
        "#log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
        "#csv_logger = CSVLogger(log_file_path, append=False)\n",
        "early_stop = EarlyStopping('val_loss', patience=patience)\n",
        "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
        "                                  patience=int(patience/4), verbose=1)\n",
        "trained_models_path = 'trained_models3'\n",
        "model_names = trained_models_path + '.{epoch:02d}.hdf5'\n",
        "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
        "                                                    save_best_only=True)\n",
        "callbacks = [model_checkpoint, early_stop, reduce_lr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DQNsaqJXWM-l",
        "colab_type": "code",
        "outputId": "e2ca68dc-18ec-4665-87ad-3a2e957fac0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5120
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])\n",
        "\n",
        "model_info = model.fit_generator(\n",
        "            train_generator,\n",
        "            \n",
        "            steps_per_epoch=950, #len(dataset)/batch_size\n",
        "            epochs=num_epoch,\n",
        "            callbacks=callbacks,\n",
        "            validation_data=validation_generator,\n",
        "            validation_steps=200,\n",
        "            workers=4,\n",
        "            shuffle=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/75\n",
            "950/950 [==============================] - 81s 85ms/step - loss: 0.3499 - acc: 0.8750 - val_loss: 0.3441 - val_acc: 0.8750\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.34411, saving model to trained_models3.01.hdf5\n",
            "Epoch 2/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.3409 - acc: 0.8754 - val_loss: 0.3362 - val_acc: 0.8754\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.34411 to 0.33620, saving model to trained_models3.02.hdf5\n",
            "Epoch 3/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.3339 - acc: 0.8759 - val_loss: 0.3318 - val_acc: 0.8760\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.33620 to 0.33184, saving model to trained_models3.03.hdf5\n",
            "Epoch 4/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.3294 - acc: 0.8768 - val_loss: 0.3267 - val_acc: 0.8770\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.33184 to 0.32668, saving model to trained_models3.04.hdf5\n",
            "Epoch 5/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.3249 - acc: 0.8780 - val_loss: 0.3230 - val_acc: 0.8783\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.32668 to 0.32297, saving model to trained_models3.05.hdf5\n",
            "Epoch 6/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.3216 - acc: 0.8786 - val_loss: 0.3168 - val_acc: 0.8798\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.32297 to 0.31677, saving model to trained_models3.06.hdf5\n",
            "Epoch 7/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.3180 - acc: 0.8797 - val_loss: 0.3141 - val_acc: 0.8805\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.31677 to 0.31410, saving model to trained_models3.07.hdf5\n",
            "Epoch 8/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.3131 - acc: 0.8810 - val_loss: 0.3106 - val_acc: 0.8823\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.31410 to 0.31056, saving model to trained_models3.08.hdf5\n",
            "Epoch 9/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.3126 - acc: 0.8811 - val_loss: 0.3051 - val_acc: 0.8828\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.31056 to 0.30507, saving model to trained_models3.09.hdf5\n",
            "Epoch 10/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.3087 - acc: 0.8824 - val_loss: 0.3063 - val_acc: 0.8833\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.30507\n",
            "Epoch 11/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.3066 - acc: 0.8832 - val_loss: 0.2997 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.30507 to 0.29968, saving model to trained_models3.11.hdf5\n",
            "Epoch 12/75\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 0.3040 - acc: 0.8839 - val_loss: 0.3010 - val_acc: 0.8845\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.29968\n",
            "Epoch 13/75\n",
            "950/950 [==============================] - 76s 81ms/step - loss: 0.3026 - acc: 0.8843 - val_loss: 0.2955 - val_acc: 0.8864\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.29968 to 0.29554, saving model to trained_models3.13.hdf5\n",
            "Epoch 14/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2988 - acc: 0.8855 - val_loss: 0.2958 - val_acc: 0.8856\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.29554\n",
            "Epoch 15/75\n",
            "950/950 [==============================] - 79s 83ms/step - loss: 0.2990 - acc: 0.8853 - val_loss: 0.2889 - val_acc: 0.8883\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.29554 to 0.28892, saving model to trained_models3.15.hdf5\n",
            "Epoch 16/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2958 - acc: 0.8866 - val_loss: 0.2913 - val_acc: 0.8879\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.28892\n",
            "Epoch 17/75\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 0.2951 - acc: 0.8863 - val_loss: 0.2877 - val_acc: 0.8891\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.28892 to 0.28774, saving model to trained_models3.17.hdf5\n",
            "Epoch 18/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2918 - acc: 0.8881 - val_loss: 0.2881 - val_acc: 0.8879\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.28774\n",
            "Epoch 19/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2909 - acc: 0.8878 - val_loss: 0.2846 - val_acc: 0.8904\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.28774 to 0.28462, saving model to trained_models3.19.hdf5\n",
            "Epoch 20/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2901 - acc: 0.8882 - val_loss: 0.2843 - val_acc: 0.8895\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.28462 to 0.28431, saving model to trained_models3.20.hdf5\n",
            "Epoch 21/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2893 - acc: 0.8884 - val_loss: 0.2830 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.28431 to 0.28301, saving model to trained_models3.21.hdf5\n",
            "Epoch 22/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2867 - acc: 0.8891 - val_loss: 0.2818 - val_acc: 0.8901\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.28301 to 0.28176, saving model to trained_models3.22.hdf5\n",
            "Epoch 23/75\n",
            "950/950 [==============================] - 79s 83ms/step - loss: 0.2873 - acc: 0.8886 - val_loss: 0.2786 - val_acc: 0.8921\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.28176 to 0.27863, saving model to trained_models3.23.hdf5\n",
            "Epoch 24/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2836 - acc: 0.8904 - val_loss: 0.2808 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.27863\n",
            "Epoch 25/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2837 - acc: 0.8899 - val_loss: 0.2767 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.27863 to 0.27667, saving model to trained_models3.25.hdf5\n",
            "Epoch 26/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2825 - acc: 0.8907 - val_loss: 0.2753 - val_acc: 0.8924\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.27667 to 0.27529, saving model to trained_models3.26.hdf5\n",
            "Epoch 27/75\n",
            "950/950 [==============================] - 79s 83ms/step - loss: 0.2810 - acc: 0.8910 - val_loss: 0.2750 - val_acc: 0.8939\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.27529 to 0.27495, saving model to trained_models3.27.hdf5\n",
            "Epoch 28/75\n",
            "950/950 [==============================] - 77s 82ms/step - loss: 0.2800 - acc: 0.8913 - val_loss: 0.2731 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.27495 to 0.27309, saving model to trained_models3.28.hdf5\n",
            "Epoch 29/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2794 - acc: 0.8914 - val_loss: 0.2733 - val_acc: 0.8934\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.27309\n",
            "Epoch 30/75\n",
            "950/950 [==============================] - 79s 83ms/step - loss: 0.2779 - acc: 0.8916 - val_loss: 0.2715 - val_acc: 0.8943\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.27309 to 0.27147, saving model to trained_models3.30.hdf5\n",
            "Epoch 31/75\n",
            "950/950 [==============================] - 79s 83ms/step - loss: 0.2776 - acc: 0.8922 - val_loss: 0.2747 - val_acc: 0.8930\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.27147\n",
            "Epoch 32/75\n",
            "950/950 [==============================] - 77s 82ms/step - loss: 0.2764 - acc: 0.8922 - val_loss: 0.2678 - val_acc: 0.8948\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.27147 to 0.26780, saving model to trained_models3.32.hdf5\n",
            "Epoch 33/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2746 - acc: 0.8931 - val_loss: 0.2660 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.26780 to 0.26605, saving model to trained_models3.33.hdf5\n",
            "Epoch 34/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2750 - acc: 0.8929 - val_loss: 0.2668 - val_acc: 0.8947\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.26605\n",
            "Epoch 35/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2744 - acc: 0.8932 - val_loss: 0.2670 - val_acc: 0.8957\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.26605\n",
            "Epoch 36/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2735 - acc: 0.8934 - val_loss: 0.2641 - val_acc: 0.8962\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.26605 to 0.26414, saving model to trained_models3.36.hdf5\n",
            "Epoch 37/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2725 - acc: 0.8937 - val_loss: 0.2672 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.26414\n",
            "Epoch 38/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2714 - acc: 0.8942 - val_loss: 0.2639 - val_acc: 0.8973\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.26414 to 0.26388, saving model to trained_models3.38.hdf5\n",
            "Epoch 39/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2703 - acc: 0.8942 - val_loss: 0.2635 - val_acc: 0.8964\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.26388 to 0.26351, saving model to trained_models3.39.hdf5\n",
            "Epoch 40/75\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 0.2696 - acc: 0.8944 - val_loss: 0.2613 - val_acc: 0.8979\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.26351 to 0.26134, saving model to trained_models3.40.hdf5\n",
            "Epoch 41/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2685 - acc: 0.8947 - val_loss: 0.2595 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.26134 to 0.25947, saving model to trained_models3.41.hdf5\n",
            "Epoch 42/75\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 0.2669 - acc: 0.8953 - val_loss: 0.2614 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.25947\n",
            "Epoch 43/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2670 - acc: 0.8950 - val_loss: 0.2603 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.25947\n",
            "Epoch 44/75\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 0.2683 - acc: 0.8948 - val_loss: 0.2600 - val_acc: 0.8974\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.25947\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 45/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2632 - acc: 0.8964 - val_loss: 0.2579 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.25947 to 0.25787, saving model to trained_models3.45.hdf5\n",
            "Epoch 46/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2632 - acc: 0.8963 - val_loss: 0.2543 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.25787 to 0.25434, saving model to trained_models3.46.hdf5\n",
            "Epoch 47/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2640 - acc: 0.8961 - val_loss: 0.2584 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.25434\n",
            "Epoch 48/75\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 0.2622 - acc: 0.8970 - val_loss: 0.2560 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.25434\n",
            "Epoch 49/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2628 - acc: 0.8966 - val_loss: 0.2556 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.25434\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 50/75\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 0.2628 - acc: 0.8966 - val_loss: 0.2574 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.25434\n",
            "Epoch 51/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2615 - acc: 0.8967 - val_loss: 0.2563 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.25434\n",
            "Epoch 52/75\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 0.2630 - acc: 0.8969 - val_loss: 0.2553 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.25434\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "Epoch 53/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2618 - acc: 0.8971 - val_loss: 0.2554 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.25434\n",
            "Epoch 54/75\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 0.2623 - acc: 0.8965 - val_loss: 0.2594 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.25434\n",
            "Epoch 55/75\n",
            "950/950 [==============================] - 77s 82ms/step - loss: 0.2627 - acc: 0.8969 - val_loss: 0.2536 - val_acc: 0.8997\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.25434 to 0.25357, saving model to trained_models3.55.hdf5\n",
            "Epoch 56/75\n",
            "950/950 [==============================] - 81s 85ms/step - loss: 0.2628 - acc: 0.8969 - val_loss: 0.2563 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.25357\n",
            "Epoch 57/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2616 - acc: 0.8968 - val_loss: 0.2565 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.25357\n",
            "Epoch 58/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2629 - acc: 0.8962 - val_loss: 0.2538 - val_acc: 0.8998\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.25357\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "Epoch 59/75\n",
            "950/950 [==============================] - 79s 83ms/step - loss: 0.2616 - acc: 0.8970 - val_loss: 0.2571 - val_acc: 0.8978\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.25357\n",
            "Epoch 60/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2624 - acc: 0.8966 - val_loss: 0.2531 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.25357 to 0.25308, saving model to trained_models3.60.hdf5\n",
            "Epoch 61/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2611 - acc: 0.8969 - val_loss: 0.2557 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.25308\n",
            "Epoch 62/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2631 - acc: 0.8962 - val_loss: 0.2558 - val_acc: 0.8995\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.25308\n",
            "Epoch 63/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2612 - acc: 0.8969 - val_loss: 0.2560 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.25308\n",
            "\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
            "Epoch 64/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2629 - acc: 0.8966 - val_loss: 0.2588 - val_acc: 0.8979\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.25308\n",
            "Epoch 65/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2613 - acc: 0.8970 - val_loss: 0.2543 - val_acc: 0.8992\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.25308\n",
            "Epoch 66/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2631 - acc: 0.8967 - val_loss: 0.2530 - val_acc: 0.8991\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.25308 to 0.25304, saving model to trained_models3.66.hdf5\n",
            "\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
            "Epoch 67/75\n",
            "950/950 [==============================] - 79s 83ms/step - loss: 0.2618 - acc: 0.8965 - val_loss: 0.2566 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.25304\n",
            "Epoch 68/75\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 0.2624 - acc: 0.8968 - val_loss: 0.2579 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.25304\n",
            "Epoch 69/75\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 0.2613 - acc: 0.8972 - val_loss: 0.2556 - val_acc: 0.8985\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.25304\n",
            "\n",
            "Epoch 00069: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
            "Epoch 70/75\n",
            "950/950 [==============================] - 77s 82ms/step - loss: 0.2624 - acc: 0.8965 - val_loss: 0.2554 - val_acc: 0.8987\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.25304\n",
            "Epoch 71/75\n",
            "800/950 [========================>.....] - ETA: 11s - loss: 0.2607 - acc: 0.8972Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}