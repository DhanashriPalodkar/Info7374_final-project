{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion_recognition Model 4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "TRBob64vzJoE",
        "colab_type": "code",
        "outputId": "219d1059-e6c6-48d0-a8c1-f808893646ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pydrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.11.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xHfI6dFnzVBq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "import tensorflow as tf\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWTkFITlz6M4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zip_file = drive.CreateFile({'id': '1C5FOGXLAAhvdaOuTWukGysyuj1NjIpVy'})\n",
        "zip_file.GetContentFile('complete_data_reduced.zip')\n",
        "validation_file = drive.CreateFile({'id':'1Xiy766wWCAo8gcNSyEFzwn2xaUHtxXqx'})\n",
        "validation_file.GetContentFile('validation_reduced.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ANLol5O0bwi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !unzip 'complete_data_reduced.zip'\n",
        "# !unzip 'validation_reduced.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LlxfHFWa1AKD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02078315-3951-4be9-bfdf-7715705bc661"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.utils.np_utils import to_categorical  \n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Convolution2D,SeparableConv2D,Conv2D\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers.pooling import MaxPooling2D,AveragePooling2D,GlobalAveragePooling2D\n",
        "from keras.layers import BatchNormalization,Activation,Input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zVcSnj9n0ndB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import glob,string\n",
        "\n",
        "## file paths training data\n",
        "angry_path = 'combined_data_reduced/angry/*'\n",
        "closed_path = 'combined_data_reduced/closed/*'\n",
        "disgust_path = 'combined_data_reduced/disgusted/*'\n",
        "fear_path = 'combined_data_reduced/fearful/*'\n",
        "happy_path = 'combined_data_reduced/happy/*'\n",
        "neutral_path = 'combined_data_reduced/neutral/*'\n",
        "sad_path = 'combined_data_reduced/sad/*'\n",
        "surprised_path = 'combined_data_reduced/surprised/*'\n",
        "\n",
        "## file path validation\n",
        "angry_path_val = 'validation_reduced/angry/*'\n",
        "closed_path_val = 'validation_reduced/closed/*'\n",
        "disgust_path_val = 'validation_reduced/disgusted/*'\n",
        "fear_path_val = 'validation_reduced/fearful/*'\n",
        "happy_path_val = 'validation_reduced/happy/*'\n",
        "neutral_path_val = 'validation_reduced/neutral/*'\n",
        "sad_path_val = 'validation_reduced/sad/*'\n",
        "surprised_path_val = 'validation_reduced/surprised/*'\n",
        "\n",
        "\n",
        "#list files training\n",
        "angry_files=glob.glob(angry_path)\n",
        "closed_files = glob.glob(closed_path)\n",
        "disgust_files = glob.glob(disgust_path)\n",
        "fear_files = glob.glob(fear_path)\n",
        "happy_files = glob.glob(happy_path)\n",
        "neutral_files = glob.glob(neutral_path)\n",
        "sad_files = glob.glob(sad_path)\n",
        "surprised_path = glob.glob(surprised_path)\n",
        "\n",
        "#list files validation\n",
        "angry_files_val=glob.glob(angry_path_val)\n",
        "closed_files_val = glob.glob(closed_path_val)\n",
        "disgust_files_val = glob.glob(disgust_path_val)\n",
        "fear_files_val = glob.glob(fear_path_val)\n",
        "happy_files_val = glob.glob(happy_path_val)\n",
        "neutral_files_val = glob.glob(neutral_path_val)\n",
        "sad_files_val = glob.glob(sad_path_val)\n",
        "surprised_path_val = glob.glob(surprised_path_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rLPjmE72LuSp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_epoch = 60\n",
        "\n",
        "training_directory='combined_data_reduced'\n",
        "validation_directory = 'validation_reduced'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mUd-DQCw05n6",
        "colab_type": "code",
        "outputId": "45e2c457-e375-44eb-e933-683cb6f6d2e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                        featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True\n",
        "                                  )\n",
        "val_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                        featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True\n",
        "                                )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        training_directory,\n",
        "        target_size=(48,48),\n",
        "        batch_size=batch_size,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_directory,\n",
        "        target_size=(48,48),\n",
        "        batch_size=batch_size,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 31527 images belonging to 8 classes.\n",
            "Found 7591 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AiLIQPVgm_oe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "    #model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=(2, 2), activation='relu'))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(256, kernel_size=(1, 1), activation='relu'))\n",
        "    model.add(Conv2D(512, kernel_size=(1, 1), activation='relu'))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(8, activation='softmax'))\n",
        " \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qPVlGSUboXR5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from keras.models import Model\n",
        "# from keras import layers\n",
        "# from keras.regularizers import l2\n",
        "# def create_model():\n",
        "#     model = Sequential()\n",
        "#     model.add(Convolution2D(filters=16, kernel_size=(3,3), padding='same',\n",
        "#                             name='image_array', input_shape=(48,48,1)))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Activation('relu'))\n",
        "#     #model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
        "#     model.add(Dropout(.25))\n",
        "\n",
        "#     model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Activation('relu'))\n",
        "#     #model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
        "#     model.add(Dropout(.25))\n",
        "\n",
        "#     model.add(Convolution2D(filters=64, kernel_size=(2, 2), padding='same'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Convolution2D(filters=128, kernel_size=(2, 2), padding='same'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Activation('relu'))\n",
        "#     model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
        "#     model.add(Dropout(.3))\n",
        "\n",
        "#     model.add(Convolution2D(filters=128, kernel_size=(2, 2), padding='same'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Convolution2D(filters=256, kernel_size=(1, 1), padding='same'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Activation('relu'))\n",
        "#     model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
        "#     model.add(Dropout(.3))\n",
        "\n",
        "#     model.add(Convolution2D(filters=256, kernel_size=(1, 1), padding='same'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Dense(512,activation='relu'))\n",
        "#     model.add(Convolution2D(\n",
        "#         filters=8, kernel_size=(3, 3), padding='same'))\n",
        "#     model.add(GlobalAveragePooling2D())\n",
        "#     model.add(Activation('softmax', name='predictions'))\n",
        "#     return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "41cDqprnn_iN",
        "colab_type": "code",
        "outputId": "c3ad16fc-b885-4557-d197-254d8a351ee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "#model = create_model2()\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 46, 46, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 44, 44, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 44, 44, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 43, 43, 128)       32896     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 21, 21, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 21, 21, 256)       33024     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 21, 21, 512)       131584    \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average (None, 10, 10, 512)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 10, 10, 512)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 2056      \n",
            "=================================================================\n",
            "Total params: 13,325,832\n",
            "Trainable params: 13,325,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eUZBR2X8HaOz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Model json"
      ]
    },
    {
      "metadata": {
        "id": "JOj5XU2uHRTN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lQubJfJgby0H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8dbf6b8c-b13a-4688-95b0-1343c840515f"
      },
      "cell_type": "code",
      "source": [
        "!mkdir 'trained_models'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘trained_models’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R85obGqYq5At",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "patience =12\n",
        "\n",
        "#log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
        "#csv_logger = CSVLogger(log_file_path, append=False)\n",
        "early_stop = EarlyStopping('val_loss', patience=patience)\n",
        "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
        "                                  patience=int(patience/4), verbose=1)\n",
        "trained_models_path = 'trained_models3'\n",
        "model_names = trained_models_path + '.{epoch:02d}.hdf5'\n",
        "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
        "                                                    save_best_only=True)\n",
        "callbacks = [model_checkpoint, early_stop, reduce_lr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CXAk4iTbnulB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4406
        },
        "outputId": "74ece900-1b72-4254-cda1-9182f93f6a40"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])\n",
        "\n",
        "model_info = model.fit_generator(\n",
        "            train_generator,\n",
        "            \n",
        "            steps_per_epoch=950, #len(dataset)/batch_size\n",
        "            epochs=num_epoch,\n",
        "            callbacks=callbacks,\n",
        "            validation_data=validation_generator,\n",
        "            validation_steps=200,\n",
        "            workers=4,\n",
        "            shuffle=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/60\n",
            "950/950 [==============================] - 114s 120ms/step - loss: 1.8368 - acc: 0.2814 - val_loss: 1.7731 - val_acc: 0.3168\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.77313, saving model to trained_models3.01.hdf5\n",
            "Epoch 2/60\n",
            "950/950 [==============================] - 110s 115ms/step - loss: 1.7327 - acc: 0.3379 - val_loss: 1.6957 - val_acc: 0.3493\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.77313 to 1.69567, saving model to trained_models3.02.hdf5\n",
            "Epoch 3/60\n",
            "950/950 [==============================] - 111s 117ms/step - loss: 1.6651 - acc: 0.3685 - val_loss: 1.6347 - val_acc: 0.3774\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.69567 to 1.63468, saving model to trained_models3.03.hdf5\n",
            "Epoch 4/60\n",
            "950/950 [==============================] - 111s 117ms/step - loss: 1.6194 - acc: 0.3899 - val_loss: 1.5846 - val_acc: 0.3940\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.63468 to 1.58465, saving model to trained_models3.04.hdf5\n",
            "Epoch 5/60\n",
            "950/950 [==============================] - 113s 119ms/step - loss: 1.5800 - acc: 0.4055 - val_loss: 1.5357 - val_acc: 0.4255\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.58465 to 1.53571, saving model to trained_models3.05.hdf5\n",
            "Epoch 6/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.5414 - acc: 0.4210 - val_loss: 1.5017 - val_acc: 0.4307\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.53571 to 1.50165, saving model to trained_models3.06.hdf5\n",
            "Epoch 7/60\n",
            "950/950 [==============================] - 109s 115ms/step - loss: 1.5111 - acc: 0.4346 - val_loss: 1.4744 - val_acc: 0.4416\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.50165 to 1.47440, saving model to trained_models3.07.hdf5\n",
            "Epoch 8/60\n",
            "950/950 [==============================] - 112s 118ms/step - loss: 1.4846 - acc: 0.4435 - val_loss: 1.4401 - val_acc: 0.4585\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.47440 to 1.44009, saving model to trained_models3.08.hdf5\n",
            "Epoch 9/60\n",
            "950/950 [==============================] - 109s 115ms/step - loss: 1.4549 - acc: 0.4537 - val_loss: 1.4217 - val_acc: 0.4624\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.44009 to 1.42167, saving model to trained_models3.09.hdf5\n",
            "Epoch 10/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.4347 - acc: 0.4627 - val_loss: 1.3794 - val_acc: 0.4813\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.42167 to 1.37936, saving model to trained_models3.10.hdf5\n",
            "Epoch 11/60\n",
            "950/950 [==============================] - 111s 116ms/step - loss: 1.4220 - acc: 0.4675 - val_loss: 1.3736 - val_acc: 0.4830\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.37936 to 1.37356, saving model to trained_models3.11.hdf5\n",
            "Epoch 12/60\n",
            "950/950 [==============================] - 109s 115ms/step - loss: 1.3993 - acc: 0.4751 - val_loss: 1.3389 - val_acc: 0.4969\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.37356 to 1.33895, saving model to trained_models3.12.hdf5\n",
            "Epoch 13/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.3812 - acc: 0.4832 - val_loss: 1.3583 - val_acc: 0.4902\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.33895\n",
            "Epoch 14/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.3684 - acc: 0.4913 - val_loss: 1.3279 - val_acc: 0.5014\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.33895 to 1.32790, saving model to trained_models3.14.hdf5\n",
            "Epoch 15/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.3564 - acc: 0.4908 - val_loss: 1.3147 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.32790 to 1.31466, saving model to trained_models3.15.hdf5\n",
            "Epoch 16/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.3444 - acc: 0.4967 - val_loss: 1.3074 - val_acc: 0.5065\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.31466 to 1.30740, saving model to trained_models3.16.hdf5\n",
            "Epoch 17/60\n",
            "950/950 [==============================] - 111s 117ms/step - loss: 1.3319 - acc: 0.5015 - val_loss: 1.2793 - val_acc: 0.5199\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.30740 to 1.27933, saving model to trained_models3.17.hdf5\n",
            "Epoch 18/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.3218 - acc: 0.5066 - val_loss: 1.2846 - val_acc: 0.5156\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.27933\n",
            "Epoch 19/60\n",
            "950/950 [==============================] - 111s 117ms/step - loss: 1.3106 - acc: 0.5122 - val_loss: 1.2678 - val_acc: 0.5231\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.27933 to 1.26777, saving model to trained_models3.19.hdf5\n",
            "Epoch 20/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.3013 - acc: 0.5143 - val_loss: 1.2669 - val_acc: 0.5230\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.26777 to 1.26694, saving model to trained_models3.20.hdf5\n",
            "Epoch 21/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.2920 - acc: 0.5165 - val_loss: 1.2807 - val_acc: 0.5148\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.26694\n",
            "Epoch 22/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.2798 - acc: 0.5225 - val_loss: 1.2408 - val_acc: 0.5306\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.26694 to 1.24077, saving model to trained_models3.22.hdf5\n",
            "Epoch 23/60\n",
            "950/950 [==============================] - 111s 117ms/step - loss: 1.2772 - acc: 0.5231 - val_loss: 1.2461 - val_acc: 0.5308\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.24077\n",
            "Epoch 24/60\n",
            "950/950 [==============================] - 110s 115ms/step - loss: 1.2652 - acc: 0.5289 - val_loss: 1.2263 - val_acc: 0.5392\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.24077 to 1.22628, saving model to trained_models3.24.hdf5\n",
            "Epoch 25/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.2542 - acc: 0.5323 - val_loss: 1.2236 - val_acc: 0.5391\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.22628 to 1.22363, saving model to trained_models3.25.hdf5\n",
            "Epoch 26/60\n",
            "950/950 [==============================] - 112s 117ms/step - loss: 1.2488 - acc: 0.5342 - val_loss: 1.2267 - val_acc: 0.5368\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.22363\n",
            "Epoch 27/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.2419 - acc: 0.5370 - val_loss: 1.1996 - val_acc: 0.5468\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.22363 to 1.19959, saving model to trained_models3.27.hdf5\n",
            "Epoch 28/60\n",
            "950/950 [==============================] - 112s 118ms/step - loss: 1.2355 - acc: 0.5373 - val_loss: 1.2075 - val_acc: 0.5509\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.19959\n",
            "Epoch 29/60\n",
            "950/950 [==============================] - 111s 117ms/step - loss: 1.2248 - acc: 0.5415 - val_loss: 1.2046 - val_acc: 0.5464\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.19959\n",
            "Epoch 30/60\n",
            "950/950 [==============================] - 111s 117ms/step - loss: 1.2226 - acc: 0.5447 - val_loss: 1.1997 - val_acc: 0.5453\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.19959\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 31/60\n",
            "950/950 [==============================] - 112s 118ms/step - loss: 1.1978 - acc: 0.5529 - val_loss: 1.1767 - val_acc: 0.5613\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.19959 to 1.17668, saving model to trained_models3.31.hdf5\n",
            "Epoch 32/60\n",
            "950/950 [==============================] - 110s 115ms/step - loss: 1.1873 - acc: 0.5571 - val_loss: 1.1764 - val_acc: 0.5574\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.17668 to 1.17637, saving model to trained_models3.32.hdf5\n",
            "Epoch 33/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.1856 - acc: 0.5597 - val_loss: 1.1676 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.17637 to 1.16765, saving model to trained_models3.33.hdf5\n",
            "Epoch 34/60\n",
            "950/950 [==============================] - 115s 122ms/step - loss: 1.1897 - acc: 0.5564 - val_loss: 1.1711 - val_acc: 0.5561\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.16765\n",
            "Epoch 35/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.1857 - acc: 0.5578 - val_loss: 1.1769 - val_acc: 0.5588\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.16765\n",
            "Epoch 36/60\n",
            "950/950 [==============================] - 114s 120ms/step - loss: 1.1777 - acc: 0.5624 - val_loss: 1.1702 - val_acc: 0.5588\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.16765\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 37/60\n",
            "950/950 [==============================] - 111s 117ms/step - loss: 1.1796 - acc: 0.5592 - val_loss: 1.1695 - val_acc: 0.5612\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.16765\n",
            "Epoch 38/60\n",
            "950/950 [==============================] - 114s 120ms/step - loss: 1.1792 - acc: 0.5596 - val_loss: 1.1643 - val_acc: 0.5614\n",
            "\n",
            "Epoch 00038: val_loss improved from 1.16765 to 1.16435, saving model to trained_models3.38.hdf5\n",
            "Epoch 39/60\n",
            "950/950 [==============================] - 114s 120ms/step - loss: 1.1755 - acc: 0.5617 - val_loss: 1.1582 - val_acc: 0.5637\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.16435 to 1.15819, saving model to trained_models3.39.hdf5\n",
            "Epoch 40/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.1778 - acc: 0.5611 - val_loss: 1.1674 - val_acc: 0.5630\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.15819\n",
            "Epoch 41/60\n",
            "950/950 [==============================] - 113s 119ms/step - loss: 1.1784 - acc: 0.5617 - val_loss: 1.1627 - val_acc: 0.5623\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.15819\n",
            "Epoch 42/60\n",
            "950/950 [==============================] - 112s 118ms/step - loss: 1.1729 - acc: 0.5620 - val_loss: 1.1634 - val_acc: 0.5649\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.15819\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "Epoch 43/60\n",
            "950/950 [==============================] - 110s 116ms/step - loss: 1.1799 - acc: 0.5606 - val_loss: 1.1730 - val_acc: 0.5603\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.15819\n",
            "Epoch 44/60\n",
            "950/950 [==============================] - 111s 117ms/step - loss: 1.1778 - acc: 0.5604 - val_loss: 1.1611 - val_acc: 0.5651\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.15819\n",
            "Epoch 45/60\n",
            "950/950 [==============================] - 111s 117ms/step - loss: 1.1785 - acc: 0.5629 - val_loss: 1.1662 - val_acc: 0.5623\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.15819\n",
            "\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "Epoch 46/60\n",
            "950/950 [==============================] - 111s 117ms/step - loss: 1.1792 - acc: 0.5614 - val_loss: 1.1638 - val_acc: 0.5636\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.15819\n",
            "Epoch 47/60\n",
            "950/950 [==============================] - 112s 118ms/step - loss: 1.1792 - acc: 0.5612 - val_loss: 1.1635 - val_acc: 0.5632\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.15819\n",
            "Epoch 48/60\n",
            "950/950 [==============================] - 111s 117ms/step - loss: 1.1780 - acc: 0.5616 - val_loss: 1.1695 - val_acc: 0.5643\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.15819\n",
            "\n",
            "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
            "Epoch 49/60\n",
            "950/950 [==============================] - 112s 118ms/step - loss: 1.1697 - acc: 0.5618 - val_loss: 1.1686 - val_acc: 0.5627\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.15819\n",
            "Epoch 50/60\n",
            "950/950 [==============================] - 112s 118ms/step - loss: 1.1781 - acc: 0.5608 - val_loss: 1.1671 - val_acc: 0.5563\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.15819\n",
            "Epoch 51/60\n",
            "950/950 [==============================] - 113s 119ms/step - loss: 1.1806 - acc: 0.5607 - val_loss: 1.1571 - val_acc: 0.5649\n",
            "\n",
            "Epoch 00051: val_loss improved from 1.15819 to 1.15713, saving model to trained_models3.51.hdf5\n",
            "Epoch 52/60\n",
            "950/950 [==============================] - 115s 121ms/step - loss: 1.1792 - acc: 0.5590 - val_loss: 1.1669 - val_acc: 0.5580\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 1.15713\n",
            "Epoch 53/60\n",
            "950/950 [==============================] - 113s 119ms/step - loss: 1.1776 - acc: 0.5596 - val_loss: 1.1594 - val_acc: 0.5636\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 1.15713\n",
            "Epoch 54/60\n",
            "950/950 [==============================] - 112s 118ms/step - loss: 1.1801 - acc: 0.5589 - val_loss: 1.1701 - val_acc: 0.5551\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 1.15713\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
            "Epoch 55/60\n",
            "950/950 [==============================] - 113s 119ms/step - loss: 1.1754 - acc: 0.5609 - val_loss: 1.1684 - val_acc: 0.5629\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 1.15713\n",
            "Epoch 56/60\n",
            "950/950 [==============================] - 112s 118ms/step - loss: 1.1765 - acc: 0.5614 - val_loss: 1.1562 - val_acc: 0.5647\n",
            "\n",
            "Epoch 00056: val_loss improved from 1.15713 to 1.15618, saving model to trained_models3.56.hdf5\n",
            "Epoch 57/60\n",
            "950/950 [==============================] - 111s 117ms/step - loss: 1.1753 - acc: 0.5603 - val_loss: 1.1631 - val_acc: 0.5675\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 1.15618\n",
            "Epoch 58/60\n",
            "950/950 [==============================] - 112s 118ms/step - loss: 1.1761 - acc: 0.5599 - val_loss: 1.1688 - val_acc: 0.5597\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 1.15618\n",
            "Epoch 59/60\n",
            "950/950 [==============================] - 111s 117ms/step - loss: 1.1818 - acc: 0.5602 - val_loss: 1.1718 - val_acc: 0.5603\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 1.15618\n",
            "\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
            "Epoch 60/60\n",
            "950/950 [==============================] - 109s 115ms/step - loss: 1.1753 - acc: 0.5615 - val_loss: 1.1649 - val_acc: 0.5635\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 1.15618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SHK8IWlvnqlT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bottleneck Features"
      ]
    },
    {
      "metadata": {
        "id": "U0H6HP9kvfzy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from keras.applications.resnet50 import ResNet50\n",
        "# datagen = ImageDataGenerator() \n",
        "# train_generator = datagen.flow_from_directory(training_directory, target_size=(48,48),shuffle=False,class_mode='categorical' ,batch_size=9)\n",
        "\n",
        "#     # get bottleneck features\n",
        "#     # use pre-trained model and exclude top layer - which is used for classification\n",
        "# pretrained_model = ResNet50(include_top=False, weights='imagenet')\n",
        "\n",
        "# #InceptionV3(include_top=False, weights='imagenet', input_shape=(48,48,1))\n",
        "# bottleneck_features_train_v1 = pretrained_model.predict_generator(train_generator,len(train_generator.filenames)//9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FxrgkNzXwlq5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# np.save('bottleneck_features_train.npy', bottleneck_features_train_v1)\n",
        "# # bottleneck_features_train_v1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qmo5O11INpZG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_generator = datagen.flow_from_directory(\n",
        "        validation_directory,\n",
        "        target_size=(48, 48),\n",
        "        batch_size=15,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "bottleneck_features_validation = pretrained_model.predict_generator(val_generator,len(val_generator.filenames)//15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3rgPoisJQvrR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save('bottleneck_features_validation.npy', bottleneck_features_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KxLs1rncSSwG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = np.load('bottleneck_features_train.npy')\n",
        "validation_data = np.load('bottleneck_features_validation.npy')\n",
        "num_classes = len(train_generator.class_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "elGM0mXdcOoZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen_top = ImageDataGenerator(rescale=1./255)  \n",
        "generator_top = datagen_top.flow_from_directory(  \n",
        "         training_directory,  \n",
        "         target_size=(48, 48),  \n",
        "         batch_size=batch_size,  \n",
        "         class_mode='categorical',  \n",
        "         shuffle=False)  \n",
        "   \n",
        "   \n",
        "train_labels = generator_top.classes  \n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O2gGDP7jx_60",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tPP2NrtOwvSz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator_top = datagen_top.flow_from_directory(  \n",
        "         validation_directory,  \n",
        "         target_size=(48, 48),  \n",
        "         batch_size=batch_size,  \n",
        "         class_mode='categorical',  \n",
        "         shuffle=False)  \n",
        "      \n",
        "validation_labels = generator_top.classes  \n",
        "validation_labels = to_categorical(validation_labels, num_classes=num_classes)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "azNIs1RHfGJ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape = train_data.shape[1:]))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(output_dim = num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Exqz5v4fIIZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S1EVq5gygRem",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(lr=0.001),metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data,train_labels,\n",
        "          epochs=50,\n",
        "          batch_size = 16,\n",
        "          validation_data = (validation_data,validation_labels),\n",
        "          callbacks = callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mU9VfCreNS-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}