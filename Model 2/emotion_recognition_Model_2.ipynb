{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion_recognition Model 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "SeiP9arIWye6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "84e9b46c-63a5-469e-c9f8-915f03b11543"
      },
      "cell_type": "code",
      "source": [
        "!pip install pydrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (1.11.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "32bTOWY_YCgW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "import tensorflow as tf\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yuEh9C4tYG71",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zip_file = drive.CreateFile({'id': '1C5FOGXLAAhvdaOuTWukGysyuj1NjIpVy'})\n",
        "zip_file.GetContentFile('complete_data_reduced.zip')\n",
        "validation_file = drive.CreateFile({'id':'1Xiy766wWCAo8gcNSyEFzwn2xaUHtxXqx'})\n",
        "validation_file.GetContentFile('validation_reduced.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2GH_TYO0YJ_u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !unzip 'complete_data_reduced.zip'\n",
        "# !unzip 'validation_reduced.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RiYBKPHIYO80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2cf8c69-0508-4912-9ab8-12cf69823ca3"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.utils.np_utils import to_categorical  \n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Convolution2D,SeparableConv2D,Conv2D\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers.pooling import MaxPooling2D,AveragePooling2D,GlobalAveragePooling2D\n",
        "from keras.layers import BatchNormalization,Activation,Input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "2t1O3-y7YYK-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import glob,string\n",
        "\n",
        "## file paths training data\n",
        "angry_path = 'combined_data_reduced/angry/*'\n",
        "closed_path = 'combined_data_reduced/closed/*'\n",
        "disgust_path = 'combined_data_reduced/disgusted/*'\n",
        "fear_path = 'combined_data_reduced/fearful/*'\n",
        "happy_path = 'combined_data_reduced/happy/*'\n",
        "neutral_path = 'combined_data_reduced/neutral/*'\n",
        "sad_path = 'combined_data_reduced/sad/*'\n",
        "surprised_path = 'combined_data_reduced/surprised/*'\n",
        "\n",
        "## file path validation\n",
        "angry_path_val = 'validation_reduced/angry/*'\n",
        "closed_path_val = 'validation_reduced/closed/*'\n",
        "disgust_path_val = 'validation_reduced/disgusted/*'\n",
        "fear_path_val = 'validation_reduced/fearful/*'\n",
        "happy_path_val = 'validation_reduced/happy/*'\n",
        "neutral_path_val = 'validation_reduced/neutral/*'\n",
        "sad_path_val = 'validation_reduced/sad/*'\n",
        "surprised_path_val = 'validation_reduced/surprised/*'\n",
        "\n",
        "\n",
        "#list files training\n",
        "angry_files=glob.glob(angry_path)\n",
        "closed_files = glob.glob(closed_path)\n",
        "disgust_files = glob.glob(disgust_path)\n",
        "fear_files = glob.glob(fear_path)\n",
        "happy_files = glob.glob(happy_path)\n",
        "neutral_files = glob.glob(neutral_path)\n",
        "sad_files = glob.glob(sad_path)\n",
        "surprised_path = glob.glob(surprised_path)\n",
        "\n",
        "#list files validation\n",
        "angry_files_val=glob.glob(angry_path_val)\n",
        "closed_files_val = glob.glob(closed_path_val)\n",
        "disgust_files_val = glob.glob(disgust_path_val)\n",
        "fear_files_val = glob.glob(fear_path_val)\n",
        "happy_files_val = glob.glob(happy_path_val)\n",
        "neutral_files_val = glob.glob(neutral_path_val)\n",
        "sad_files_val = glob.glob(sad_path_val)\n",
        "surprised_path_val = glob.glob(surprised_path_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "np1eZSKSYchM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_epoch = 30\n",
        "\n",
        "training_directory='combined_data_reduced'\n",
        "validation_directory = 'validation_reduced'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YSFlIkmBZM0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e6f485b4-8df0-4eeb-d0d1-26f495aa0e59"
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                        featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True\n",
        "                                  )\n",
        "val_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                        featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True\n",
        "                                )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        training_directory,\n",
        "        target_size=(48,48),\n",
        "        batch_size=batch_size,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_directory,\n",
        "        target_size=(48,48),\n",
        "        batch_size=batch_size,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 31527 images belonging to 8 classes.\n",
            "Found 7591 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pdRBt1_LZVW3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
        "#     model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=(2, 2), activation='relu'))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(256, kernel_size=(1, 1), activation='relu'))\n",
        "    model.add(Conv2D(512, kernel_size=(1, 1), activation='relu'))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(8, activation='softmax'))\n",
        " \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1xVS3RlrZZnn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "bd3a5068-5e40-4561-f208-a0da7b58b7ff"
      },
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "#model = create_model2()\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 46, 46, 32)        320       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 22, 22, 128)       16512     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 256)       33024     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 512)       131584    \n",
            "_________________________________________________________________\n",
            "average_pooling2d_3 (Average (None, 5, 5, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               3277056   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 2056      \n",
            "=================================================================\n",
            "Total params: 3,460,552\n",
            "Trainable params: 3,460,552\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XnCOUqp_ZeUp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rZ50zfDSZky5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "490404de-93d3-4f39-8e3e-36b547b1ab46"
      },
      "cell_type": "code",
      "source": [
        "!mkdir 'trained_models'"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘trained_models’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-Oj8ZGEtZn3B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "patience =12\n",
        "\n",
        "#log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
        "#csv_logger = CSVLogger(log_file_path, append=False)\n",
        "early_stop = EarlyStopping('val_loss', patience=patience)\n",
        "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
        "                                  patience=int(patience/4), verbose=1)\n",
        "trained_models_path = 'trained_models3'\n",
        "model_names = trained_models_path + '.{epoch:02d}.hdf5'\n",
        "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
        "                                                    save_best_only=True)\n",
        "callbacks = [model_checkpoint, early_stop, reduce_lr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iQ4ESLXSZtnj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2128
        },
        "outputId": "8ab5c678-fbe3-408c-c69a-01b4216a9a15"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])\n",
        "\n",
        "model_info = model.fit_generator(\n",
        "            train_generator,\n",
        "            \n",
        "            steps_per_epoch=950, #len(dataset)/batch_size\n",
        "            epochs=num_epoch,\n",
        "            callbacks=callbacks,\n",
        "            validation_data=validation_generator,\n",
        "            validation_steps=200,\n",
        "            workers=4,\n",
        "            shuffle=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/30\n",
            "950/950 [==============================] - 83s 87ms/step - loss: 1.9025 - acc: 0.2365 - val_loss: 1.8719 - val_acc: 0.2594\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.87186, saving model to trained_models3.01.hdf5\n",
            "Epoch 2/30\n",
            "950/950 [==============================] - 79s 83ms/step - loss: 1.8497 - acc: 0.2732 - val_loss: 1.8330 - val_acc: 0.2919\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.87186 to 1.83304, saving model to trained_models3.02.hdf5\n",
            "Epoch 3/30\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 1.8154 - acc: 0.2930 - val_loss: 1.7961 - val_acc: 0.2993\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.83304 to 1.79614, saving model to trained_models3.03.hdf5\n",
            "Epoch 4/30\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 1.7828 - acc: 0.3116 - val_loss: 1.7719 - val_acc: 0.3053\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.79614 to 1.77190, saving model to trained_models3.04.hdf5\n",
            "Epoch 5/30\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 1.7657 - acc: 0.3182 - val_loss: 1.7395 - val_acc: 0.3327\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.77190 to 1.73946, saving model to trained_models3.05.hdf5\n",
            "Epoch 6/30\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 1.7457 - acc: 0.3320 - val_loss: 1.7347 - val_acc: 0.3289\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.73946 to 1.73469, saving model to trained_models3.06.hdf5\n",
            "Epoch 7/30\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 1.7275 - acc: 0.3417 - val_loss: 1.7076 - val_acc: 0.3405\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.73469 to 1.70762, saving model to trained_models3.07.hdf5\n",
            "Epoch 8/30\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 1.7119 - acc: 0.3475 - val_loss: 1.7000 - val_acc: 0.3525\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.70762 to 1.69996, saving model to trained_models3.08.hdf5\n",
            "Epoch 9/30\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 1.6938 - acc: 0.3521 - val_loss: 1.6750 - val_acc: 0.3562\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.69996 to 1.67501, saving model to trained_models3.09.hdf5\n",
            "Epoch 10/30\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 1.6830 - acc: 0.3619 - val_loss: 1.6755 - val_acc: 0.3741\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.67501\n",
            "Epoch 11/30\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 1.6702 - acc: 0.3688 - val_loss: 1.6571 - val_acc: 0.3611\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.67501 to 1.65705, saving model to trained_models3.11.hdf5\n",
            "Epoch 12/30\n",
            "950/950 [==============================] - 75s 79ms/step - loss: 1.6579 - acc: 0.3708 - val_loss: 1.6202 - val_acc: 0.3860\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.65705 to 1.62017, saving model to trained_models3.12.hdf5\n",
            "Epoch 13/30\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 1.6419 - acc: 0.3794 - val_loss: 1.6227 - val_acc: 0.3889\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.62017\n",
            "Epoch 14/30\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 1.6283 - acc: 0.3845 - val_loss: 1.5975 - val_acc: 0.3975\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.62017 to 1.59755, saving model to trained_models3.14.hdf5\n",
            "Epoch 15/30\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 1.6198 - acc: 0.3866 - val_loss: 1.5922 - val_acc: 0.3970\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.59755 to 1.59224, saving model to trained_models3.15.hdf5\n",
            "Epoch 16/30\n",
            "950/950 [==============================] - 75s 79ms/step - loss: 1.6047 - acc: 0.3954 - val_loss: 1.5635 - val_acc: 0.4158\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.59224 to 1.56349, saving model to trained_models3.16.hdf5\n",
            "Epoch 17/30\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 1.5993 - acc: 0.3964 - val_loss: 1.5800 - val_acc: 0.3991\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.56349\n",
            "Epoch 18/30\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 1.5847 - acc: 0.4013 - val_loss: 1.5589 - val_acc: 0.4155\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.56349 to 1.55885, saving model to trained_models3.18.hdf5\n",
            "Epoch 19/30\n",
            "950/950 [==============================] - 74s 78ms/step - loss: 1.5797 - acc: 0.4018 - val_loss: 1.5553 - val_acc: 0.4139\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.55885 to 1.55531, saving model to trained_models3.19.hdf5\n",
            "Epoch 20/30\n",
            "950/950 [==============================] - 75s 79ms/step - loss: 1.5725 - acc: 0.4069 - val_loss: 1.5565 - val_acc: 0.4069\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.55531\n",
            "Epoch 21/30\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 1.5621 - acc: 0.4157 - val_loss: 1.5347 - val_acc: 0.4166\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.55531 to 1.53473, saving model to trained_models3.21.hdf5\n",
            "Epoch 22/30\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 1.5521 - acc: 0.4185 - val_loss: 1.5258 - val_acc: 0.4309\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.53473 to 1.52579, saving model to trained_models3.22.hdf5\n",
            "Epoch 23/30\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 1.5531 - acc: 0.4173 - val_loss: 1.5303 - val_acc: 0.4216\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.52579\n",
            "Epoch 24/30\n",
            "950/950 [==============================] - 76s 80ms/step - loss: 1.5378 - acc: 0.4217 - val_loss: 1.5049 - val_acc: 0.4364\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.52579 to 1.50490, saving model to trained_models3.24.hdf5\n",
            "Epoch 25/30\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 1.5401 - acc: 0.4203 - val_loss: 1.5056 - val_acc: 0.4367\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.50490\n",
            "Epoch 26/30\n",
            "950/950 [==============================] - 79s 83ms/step - loss: 1.5295 - acc: 0.4277 - val_loss: 1.4946 - val_acc: 0.4375\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.50490 to 1.49458, saving model to trained_models3.26.hdf5\n",
            "Epoch 27/30\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 1.5202 - acc: 0.4290 - val_loss: 1.4976 - val_acc: 0.4395\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.49458\n",
            "Epoch 28/30\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 1.5142 - acc: 0.4298 - val_loss: 1.4831 - val_acc: 0.4329\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.49458 to 1.48312, saving model to trained_models3.28.hdf5\n",
            "Epoch 29/30\n",
            "950/950 [==============================] - 78s 82ms/step - loss: 1.5034 - acc: 0.4328 - val_loss: 1.4850 - val_acc: 0.4397\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.48312\n",
            "Epoch 30/30\n",
            "950/950 [==============================] - 77s 81ms/step - loss: 1.5039 - acc: 0.4348 - val_loss: 1.4335 - val_acc: 0.4631\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.48312 to 1.43347, saving model to trained_models3.30.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}